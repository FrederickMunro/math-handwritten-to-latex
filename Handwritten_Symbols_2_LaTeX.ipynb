{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TZzv25vDL9LQ"
      },
      "source": [
        "# **Handwritten Math Expressions to LaTeX**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MP7fynuIMGlg"
      },
      "source": [
        "## **Abstract**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The objective of this project was to develop a machine learning model for image classification, specifically for identifying handwritten mathematical formulas from images and converting them into LaTeX readable code. Prior to training the model, image data was preprocessed, notably by converting PNG files to grayscale tensors and loading them into a dataset. The project utilized a convolutional neural network (CNN) with an encoder-decoder architecture for feature extraction and image reconstruction, as well as recurrent neural networks (RNNs) with long short-term memory (LSTM) cells for sequence modeling and capturing long-term dependencies in the data. However, due to various issues encountered during training, the model was not able to read entire expressions in time. As a result, the model discussed in this report is currently limited to reading individual mathematical symbols."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wBGDBctaMYYQ"
      },
      "source": [
        "## **Introduction**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Problem Statement** ###"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The problem being addressed in this project is the development of a machine learning model for image classification of handwritten mathematical formulas and converting them into their respective LaTeX readable code. This is an important problem as it has potential applications in various fields, such as education, document processing, and scientific research, where automated recognition and conversion of handwritten math symbols can greatly enhance efficiency and accuracy."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Challenges** ###"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The main challenges in solving this problem include the variability in handwriting styles, the complexity of mathematical symbols and expressions, and the need to capture both local features and global dependencies in the images. Previous attempts to solve this problem have utilized various techniques, including traditional image processing methods, as well as deep learning approaches."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Approach** ###"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this project, a combination of convolutional neural networks (CNNs) with an encoder-decoder architecture and recurrent neural networks (RNNs) with LSTM cells is used. The CNN encoder-decoder architecture is employed for feature extraction and image reconstruction, while LSTM cells are utilized for sequence modeling and capturing long-term dependencies in the data. This approach is promising as it can potentially capture both local features and global dependencies in the images, which are important for accurately recognizing and converting handwritten math symbols."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Related Works** ###"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A related attempt at solving this problem can be examined by reading a past work conducted by V. Romero, A. Toselli, and E. Vidal, [Mathematical Symbol Recognition in Handwritten Mathematical Expressions: Techniques and Challenges](https://doi.org/10.1109/ICECA55336.2022.10009145). The proposed reading suggests implementation using various machine learning and deep learning algorithms like Logistic Regression, Convolutional Neural networks, and Dense net. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Dataset** ###"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dataset used for training and evaluation is a collection of handwritten mathematical formulas in image format, along with their corresponding LaTeX code used as labels."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Results** ###"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model achieved an accuracy of 91.72% on the training set, indicating its ability to learn from the data and capture relevant patterns. However, on the test set, the accuracy dropped to 34.98%, suggesting some overfitting issues. Nevertheless, the model showed promising results in recognizing individual mathematical symbols."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XtzOOJDnMpWp"
      },
      "source": [
        "## **Methodology**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Data Preprocessing** ###"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data preprocessing was a critical step in the project as the chosen dataset consisted of INKML files, which are not meant for training. These are XML-based files used for representing digital ink data with time-series information, including metadata such as pen pressure, pen tilt, pen velocity, pen color, and stroke labels. To prepare the data for training, the INKML files were first converted to PNG format using code obtained from Harold Mouch√®re, as provided in the dataset. The PNG images of the handwritten mathematical symbols were then converted to grayscale tensors to reduce computational complexity and normalize pixel values. These preprocessing steps helped in preparing the dataset for training a machine learning model on the handwritten mathematical symbols data.\n",
        "\n",
        "A language dictionary class was also used to create a dictionary of all the labels found in the presented dataset. The code used for this class can found on the [pytorch tutorials site](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Feature Engineering** ###"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to recognize individual mathematical symbols, it was necessary to extract relevant features from the images. For this purpose, a convolutional neural network (CNN) was used as the encoder-decoder architecture for feature extraction. The encoder part of the CNN learned to extract high-level features from the images, while the decoder part reconstructed the images from the extracted features. This feature extraction step was critical in capturing important patterns and structures in the handwritten symbols, allowing the model to learn meaningful representations from the input data."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Model Architecture** ###"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A combination of CNN and recurrent neural network (RNN) with long short-term memory (LSTM) cells was utilized for sequence modeling. The CNN encoder-decoder architecture was employed for feature extraction and image reconstruction, while the LSTM cells were used to model the sequential nature of the symbols in the expressions and capture long-term dependencies in the data. The LSTM cells also allowed for the modeling of variable-length sequences, which is a characteristic of handwritten mathematical expressions. A textual representation of the model's architexture can be seen below:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "HME2LaTeX(\n",
        "  (cnn): CNN(\n",
        "    (layer1): Sequential(\n",
        "      (0): ConvNormRelu(\n",
        "        (conv): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))\n",
        "        (batchNorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "      (1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
        "    )\n",
        "    (layer2): Sequential(\n",
        "      (0): ConvNormRelu(\n",
        "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
        "        (batchNorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "      (1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
        "    )\n",
        "    (layer3): Sequential(\n",
        "      (0): ConvNormRelu(\n",
        "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
        "        (batchNorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "      (1): ConvNormRelu(\n",
        "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
        "        (batchNorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "      (2): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
        "      (3): ConvNormRelu(\n",
        "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
        "        (batchNorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "      (4): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
        "    )\n",
        "    (layer4): ConvNormRelu(\n",
        "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
        "      (batchNorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "    )\n",
        "  )\n",
        "  (encoder): Encoder(\n",
        "    (blstm): LSTM(512, 256, bidirectional=True)\n",
        "    (linear): Linear(in_features=512, out_features=256, bias=True)\n",
        "  )\n",
        "  (decoder): Decoder(\n",
        "    (lstm): LSTM(1, 512)\n",
        "    (wout): Linear(in_features=512, out_features=100, bias=False)\n",
        "    (wf): Linear(in_features=512, out_features=1, bias=False)\n",
        "    (wh): Linear(in_features=512, out_features=1, bias=False)\n",
        "    (wc): Linear(in_features=1024, out_features=512, bias=False)\n",
        "    (softmax_out): Softmax(dim=-1)\n",
        "    (softmax_alpha): Softmax(dim=0)\n",
        "  )\n",
        ")\n",
        "```"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Model Evaluation** ###"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model was trained on a large dataset of handwritten mathematical symbols and its performance was evaluated by measuring its accuracy on a test set."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Originality**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "V. Romero, A. Toselli, and E. Vidal's attempt at solving this problem was successful but they omitted the use of RNN. The usage of this feature in this paper's model allows for analyzing long-term dependancies in the data, which can further strengthen the model's decision-making. Additionally, the model will present symbols in LaTeX format."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YIQOcLeaPq3v"
      },
      "source": [
        "## **Experimental Setup**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Dataset** ###"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Dataset used for this project is the [CROHME Dataset](https://tc11.cvc.uab.es/datasets/ICFHR-CROHME-2016_1) which contains a large set of inkML files and their respective labels. The dataset can be downloaded online but is very large so I have provided the subset that was used for the purpose of this project in the [data directory](src/data). Below is an example of what a batch would look like:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> ![visual of batch information](figures/image_prediction_target.png)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Machine Learning Techniques** ###"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here is a list of machine learning techniqures used to train the model along with their corresponding hyperparameters:\n",
        " - **Convolutional Neural Networks (CNNs)**: used for image recognition tasks and can learn hierarchical representations from image data. ([file](src/model/cnn.py))\n",
        "   - **Architecture** - four convolutional layers.\n",
        "   - **Kernel** - size of 3x3.\n",
        "   - **In/Out Channels** - size set per layer.\n",
        " - **Encoder** - uses bidirectional LSTM cells to compress the input data to better extract features. ([file](src/model/encoder.py))\n",
        "   - **Input Size** - size of the input tensor.\n",
        "   - **Hidden Size** - size of the model's hidden state.\n",
        "   - **Sequence Size** - sequence length of tensor input.\n",
        "   - **Batch Size** - the number of samples passed as a group.\n",
        " - **Decoder** - uses unidirectional LSTM cells to generate an output sequence from the encoder's output. ([file](src/model/decoder.py))\n",
        "   - **Input Size** - size of the input tensor.\n",
        "   - **Output Size** - size of the output tensor.\n",
        "   - **Hidden Size** - size of the hidden state in the LSTM.\n",
        "   - **Number of Features** - number of features in the input sequence.\n",
        "   - **Batch Size** - the number of samples passed as a group.\n",
        " - **Long Short-Term Memory (LSTM)**: a recurrent neural network (RNN) architecture that was used to capture dependencies in sequences.\n",
        "   - **Input/Hidden Sizes** - Dependant on the input and hidden sizes of either the Decoder or the Encoder.\n",
        " - **Categorical Cross Entropy Loss**: used as the loss function for this multi-class classification tasks.\n",
        " - **Stochastic Gradient Descent (SGD)**: optimizer function used to update the model parameters during training based on the gradients of the loss function.\n",
        "   - **Learning Rate** - controls the step size of the weight updates during training.\n",
        "   - **Momentum** - determines how important information from previous weight updates is when considering new weight updates.\n",
        " - **Backpropagation**: computes gradients and update the model's parameters using the optimizer.\n",
        " - **Mini-batch Training**: seperates the dataset into subsets to allow for more efficient processing. The efficiency stems from updating the model's parameters using the subsets of the data rather than individual items.\n",
        " - **Checkpointing**: the model's state dictionary, optimizer's state dictionary, loss values, and accuracy values were saved to a file. This was used to allow resuming training from a checkpoint and for model evaluation.\n",
        "\n",
        "Model Hyperparameters:\n",
        " - **Epochs** - the number of times the entire dataset is iterated through during training."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BRL5KR20QWKu"
      },
      "source": [
        "## **Experimental Results**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I initially trained the model for 10 epochs, and during training, it achieved a high mean accuracy of 91.72% in converting math symbols to their LaTeX equivalent. However, when tested on a separate testing set, the model's accuracy dropped significantly to only 34.98%. To investigate if overfitting was the issue, I decided to train another model with fewer epochs. Upon analyzing the available [metrics file](src/metrics.ipynb), specifically the graphs of accuracy and loss (as shown in the figure below), it appears that the model's performance stabilizes after around four epochs or 4692 batches.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> ![accuracy and loss during 10 epochs](figures/10_epoch_accuracy_loss.png)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "However, this approach did not yield positive results as the test set accuracy did not improve. Upon further analysis, I observed that the training and test sets had significantly different distributions of symbols, as evident from the tables below:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> ![symbol distribution training set](figures/symbol_distri_train.png)\n",
        "> ![symbol distribution testing set](figures/symbol_distri_test.png)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As evident from the data, LaTeX symbols like  ```\\tan``` and ```\\log``` are present in low quantities in the training set, but they are abundant in the testing set. This disparity in the frequency of these symbols between the two sets could be a reason for the model's poor performance on the test set. Due to the limited exposure to these symbols during training, the model may struggle to accurately predict them. The higher frequency of these symbols in the testing set intensifies the issue, leading to increased likelihood of incorrect predictions."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Comparison to Related Works**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "According to V. Romero, A. Toselli, and E. Vidal, their accuracy during the training phase reached 99%, and during the testing phasereached 94.2%. This outcome greatly surpasses the results obtained in this project. However, I am confident that a more balanced distribution of data between the training set and testing set would yield improved results."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "b4Jyn3BcQDpf"
      },
      "source": [
        "## **Conclusions**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on the experiments conducted, several conclusions can be drawn. Firstly, training the model with more epochs did not necessarily lead to improved performance on the test set. This suggests that the model may have reached a saturation point in terms of learning from the available data. Moreover, The drastic difference in symbol distributions between the training and test sets, such as the presence of LaTeX symbols in the test set that were rarely present in the training set, may have contributed to the lower performance of the model on the test set. This highlights the importance of ensuring a balanced distribution of data between the training and test sets to avoid such discrepancies. Finally, The results achieved in this project were not as favorable as those reported in related works. This suggests that there may be further opportunities to improve the model's performance through adjustments to the training data, model architecture, or hyperparameters.\n",
        "\n",
        "In conclusion, while the experiments provided insights into the performance of the model, it is important to consider the limitations and potential areas for improvement. This includes the need for a balanced distribution of data, further optimization of the model, and comparison with other state-of-the-art approaches to gain a comprehensive understanding of the results obtained."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yaxqlm6kRcmb"
      },
      "source": [
        "## **References**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**[1]**: K. Padmanandam, A. Yadav, Aishwarya and H. N, \"Handwritten Mathematical Symbol Recognition using Neural Network Architectures,\" 2022 6th International Conference on Electronics, Communication and Aerospace Technology, Coimbatore, India, 2022, pp. 1325-1329, doi: 10.1109/ICECA55336.2022.10009145."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
